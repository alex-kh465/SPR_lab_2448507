{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b952b830",
   "metadata": {},
   "source": [
    "# Lab Exercise V ‚Äì Time Alignment and Normalization\n",
    "\n",
    "**Name:** Alex  \n",
    "**Roll Number:** 2448507  \n",
    "**Date:** November 17, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Aim\n",
    "To align two speech sequences of the same word spoken at different speeds using **Linear Time Normalization (LTN)** and analyze how time alignment helps in matching temporal patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## Theory\n",
    "\n",
    "### Linear Time Normalization (LTN)\n",
    "Linear Time Normalization is a technique used to align two signals of different lengths by linearly scaling the time axis of one signal to match the other. This is particularly useful in speech processing where:\n",
    "\n",
    "- **Different Speaking Rates:** The same word spoken by different people or at different times may have different durations\n",
    "- **Temporal Pattern Matching:** To compare two signals effectively, they need to have the same length\n",
    "- **Feature Alignment:** Before computing similarity measures, signals must be temporally aligned\n",
    "\n",
    "### Key Concepts\n",
    "1. **Reference Signal:** The signal whose length we want to match (Signal 1)\n",
    "2. **Test Signal:** The signal that needs to be normalized (Signal 2)\n",
    "3. **Interpolation:** The process of estimating values at new time points to resize the signal\n",
    "4. **Alignment Path:** Shows the correspondence between samples in both signals\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60990227",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1118b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc968e0d",
   "metadata": {},
   "source": [
    "## Given Data\n",
    "\n",
    "We have two signals representing the same word spoken at different speeds:\n",
    "- **Signal 1 (Reference):** 9 samples - representing faster speech\n",
    "- **Signal 2 (Test):** 12 samples - representing slower speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given speech signals\n",
    "signal1 = np.array([0.2, 0.4, 0.6, 0.8, 1.0, 0.8, 0.6, 0.4, 0.2])  # Reference (faster)\n",
    "signal2 = np.array([0.2, 0.3, 0.5, 0.7, 0.9, 1.0, 0.9, 0.7, 0.5, 0.4, 0.3, 0.2])  # Test (slower)\n",
    "\n",
    "# Display signal information\n",
    "print(\"=\"*60)\n",
    "print(\"SIGNAL INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Signal 1 (Reference):\")\n",
    "print(f\"  Length: {len(signal1)} samples\")\n",
    "print(f\"  Values: {signal1}\")\n",
    "print(f\"  Min: {signal1.min():.2f}, Max: {signal1.max():.2f}\")\n",
    "print()\n",
    "print(f\"Signal 2 (Test):\")\n",
    "print(f\"  Length: {len(signal2)} samples\")\n",
    "print(f\"  Values: {signal2}\")\n",
    "print(f\"  Min: {signal2.min():.2f}, Max: {signal2.max():.2f}\")\n",
    "print()\n",
    "print(f\"Length Difference: {len(signal2) - len(signal1)} samples\")\n",
    "print(f\"Ratio: {len(signal2)/len(signal1):.2f}x (Signal 2 is {((len(signal2)/len(signal1)-1)*100):.1f}% longer)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e988606d",
   "metadata": {},
   "source": [
    "## Task 1: Plot Both Speech Signals\n",
    "\n",
    "First, we visualize both signals to observe their differences in:\n",
    "- **Length:** Signal 2 has more samples (slower speech)\n",
    "- **Amplitude Patterns:** Both signals should show similar envelope patterns\n",
    "- **Temporal Characteristics:** Signal 2 is stretched in time compared to Signal 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time axes for both signals\n",
    "time1 = np.arange(len(signal1))\n",
    "time2 = np.arange(len(signal2))\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Plot Signal 1 (Reference)\n",
    "axes[0].plot(time1, signal1, 'b-o', linewidth=2, markersize=8, label='Signal 1 (Reference)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlabel('Sample Index', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Amplitude', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Signal 1 (Reference) - Faster Speech (9 samples)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='upper right', fontsize=11)\n",
    "axes[0].set_ylim([0, 1.1])\n",
    "axes[0].axhline(y=1.0, color='r', linestyle='--', alpha=0.3, label='Peak')\n",
    "\n",
    "# Add annotations for key points\n",
    "peak_idx1 = np.argmax(signal1)\n",
    "axes[0].annotate(f'Peak: {signal1[peak_idx1]:.1f}', \n",
    "                xy=(peak_idx1, signal1[peak_idx1]), \n",
    "                xytext=(peak_idx1+0.5, signal1[peak_idx1]+0.1),\n",
    "                arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "                fontsize=10, fontweight='bold', color='red')\n",
    "\n",
    "# Plot Signal 2 (Test)\n",
    "axes[1].plot(time2, signal2, 'g-s', linewidth=2, markersize=8, label='Signal 2 (Test)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xlabel('Sample Index', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Amplitude', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Signal 2 (Test) - Slower Speech (12 samples)', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='upper right', fontsize=11)\n",
    "axes[1].set_ylim([0, 1.1])\n",
    "axes[1].axhline(y=1.0, color='r', linestyle='--', alpha=0.3, label='Peak')\n",
    "\n",
    "# Add annotations for key points\n",
    "peak_idx2 = np.argmax(signal2)\n",
    "axes[1].annotate(f'Peak: {signal2[peak_idx2]:.1f}', \n",
    "                xy=(peak_idx2, signal2[peak_idx2]), \n",
    "                xytext=(peak_idx2+0.5, signal2[peak_idx2]+0.1),\n",
    "                arrowprops=dict(arrowstyle='->', color='red', lw=1.5),\n",
    "                fontsize=10, fontweight='bold', color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('task1_original_signals.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä OBSERVATION:\")\n",
    "print(f\"  ‚Ä¢ Signal 1 has {len(signal1)} samples (faster speech)\")\n",
    "print(f\"  ‚Ä¢ Signal 2 has {len(signal2)} samples (slower speech)\")\n",
    "print(f\"  ‚Ä¢ Signal 2 is {len(signal2)-len(signal1)} samples longer\")\n",
    "print(f\"  ‚Ä¢ Both signals show similar envelope patterns with peaks at 1.0\")\n",
    "print(f\"  ‚Ä¢ Signal 2 is stretched in time compared to Signal 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c147e9",
   "metadata": {},
   "source": [
    "## Task 2: Perform Linear Time Normalization\n",
    "\n",
    "### Methodology\n",
    "We will use **linear interpolation** to normalize Signal 2 to match the length of Signal 1:\n",
    "\n",
    "1. **Original Time Axis:** Create a time axis for Signal 2 with 12 points\n",
    "2. **Target Time Axis:** Create a time axis for Signal 1 with 9 points\n",
    "3. **Interpolation:** Use `scipy.interpolate.interp1d` to estimate values at the new time points\n",
    "4. **Resampling:** Generate the normalized signal with 9 samples\n",
    "\n",
    "This process linearly compresses Signal 2 to match the temporal structure of Signal 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75685daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_time_normalization(signal_to_normalize, target_length):\n",
    "    \"\"\"\n",
    "    Perform Linear Time Normalization (LTN) on a signal.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal_to_normalize : numpy array\n",
    "        The input signal to be normalized\n",
    "    target_length : int\n",
    "        The desired length of the output signal\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    normalized_signal : numpy array\n",
    "        The normalized signal with target_length samples\n",
    "    \"\"\"\n",
    "    # Create original time axis (normalized to [0, 1])\n",
    "    original_time = np.linspace(0, 1, len(signal_to_normalize))\n",
    "    \n",
    "    # Create target time axis (normalized to [0, 1])\n",
    "    target_time = np.linspace(0, 1, target_length)\n",
    "    \n",
    "    # Create interpolation function (linear)\n",
    "    interpolator = interpolate.interp1d(original_time, signal_to_normalize, kind='linear')\n",
    "    \n",
    "    # Generate normalized signal\n",
    "    normalized_signal = interpolator(target_time)\n",
    "    \n",
    "    return normalized_signal\n",
    "\n",
    "\n",
    "# Perform Linear Time Normalization on Signal 2\n",
    "print(\"Performing Linear Time Normalization...\\n\")\n",
    "signal2_normalized = linear_time_normalization(signal2, len(signal1))\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*60)\n",
    "print(\"LINEAR TIME NORMALIZATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original Signal 2 length: {len(signal2)} samples\")\n",
    "print(f\"Target length (Signal 1): {len(signal1)} samples\")\n",
    "print(f\"Normalized Signal 2 length: {len(signal2_normalized)} samples\")\n",
    "print()\n",
    "print(\"Original Signal 2:\")\n",
    "print(f\"  {signal2}\")\n",
    "print()\n",
    "print(\"Normalized Signal 2:\")\n",
    "print(f\"  {np.round(signal2_normalized, 4)}\")\n",
    "print()\n",
    "print(\"Signal 1 (Reference):\")\n",
    "print(f\"  {signal1}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate similarity metrics\n",
    "mse = np.mean((signal1 - signal2_normalized)**2)\n",
    "correlation = np.corrcoef(signal1, signal2_normalized)[0, 1]\n",
    "\n",
    "print(f\"\\nüìà SIMILARITY METRICS:\")\n",
    "print(f\"  ‚Ä¢ Mean Squared Error (MSE): {mse:.6f}\")\n",
    "print(f\"  ‚Ä¢ Correlation Coefficient: {correlation:.6f}\")\n",
    "print(f\"  ‚Ä¢ Normalization successful: Both signals now have {len(signal1)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42036bc4",
   "metadata": {},
   "source": [
    "### Visualization of Normalization Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6392ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Original Signal 2\n",
    "axes[0].plot(time2, signal2, 'g-s', linewidth=2, markersize=8, label='Original Signal 2 (12 samples)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlabel('Sample Index', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Amplitude', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Before Normalization: Signal 2 (Test) - 12 samples', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='upper right', fontsize=11)\n",
    "axes[0].set_ylim([0, 1.1])\n",
    "\n",
    "# Plot 2: Normalized Signal 2\n",
    "axes[1].plot(time1, signal2_normalized, 'r-^', linewidth=2, markersize=8, label='Normalized Signal 2 (9 samples)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xlabel('Sample Index', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Amplitude', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('After Normalization: Signal 2 Normalized to 9 samples', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='upper right', fontsize=11)\n",
    "axes[1].set_ylim([0, 1.1])\n",
    "\n",
    "# Plot 3: Comparison of Signal 1 and Normalized Signal 2\n",
    "axes[2].plot(time1, signal1, 'b-o', linewidth=2, markersize=8, label='Signal 1 (Reference)', alpha=0.7)\n",
    "axes[2].plot(time1, signal2_normalized, 'r-^', linewidth=2, markersize=8, label='Normalized Signal 2', alpha=0.7)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].set_xlabel('Sample Index', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Amplitude', fontsize=12, fontweight='bold')\n",
    "axes[2].set_title('Comparison: Signal 1 vs Normalized Signal 2', fontsize=14, fontweight='bold')\n",
    "axes[2].legend(loc='upper right', fontsize=11)\n",
    "axes[2].set_ylim([0, 1.1])\n",
    "\n",
    "# Add error shading\n",
    "axes[2].fill_between(time1, signal1, signal2_normalized, alpha=0.2, color='orange', label='Difference')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('task2_normalization_process.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Normalization completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb8e21",
   "metadata": {},
   "source": [
    "## Task 3: Compute Alignment Between Signals\n",
    "\n",
    "Now that both signals have the same length, we can compute a sample-to-sample alignment. This shows how each sample in Signal 1 corresponds to a sample in the normalized Signal 2.\n",
    "\n",
    "The alignment is straightforward after normalization since both signals have the same number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alignment(signal1, signal2_normalized):\n",
    "    \"\"\"\n",
    "    Compute alignment between two signals of equal length.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signal1 : numpy array\n",
    "        Reference signal\n",
    "    signal2_normalized : numpy array\n",
    "        Normalized test signal\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    alignment : list of tuples\n",
    "        List of (index_signal1, index_signal2_normalized) pairs\n",
    "    \"\"\"\n",
    "    alignment = [(i, i) for i in range(len(signal1))]\n",
    "    return alignment\n",
    "\n",
    "\n",
    "# Compute alignment\n",
    "alignment = compute_alignment(signal1, signal2_normalized)\n",
    "\n",
    "# Display alignment information\n",
    "print(\"=\"*70)\n",
    "print(\"ALIGNMENT COMPUTATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Index':<8} {'Signal 1':<12} {'Norm. Signal 2':<18} {'Difference':<12}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for i, (idx1, idx2) in enumerate(alignment):\n",
    "    diff = signal1[idx1] - signal2_normalized[idx2]\n",
    "    print(f\"{i:<8} {signal1[idx1]:<12.4f} {signal2_normalized[idx2]:<18.4f} {diff:<12.6f}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate alignment statistics\n",
    "differences = np.abs(signal1 - signal2_normalized)\n",
    "print(f\"\\nüìä ALIGNMENT STATISTICS:\")\n",
    "print(f\"  ‚Ä¢ Total aligned points: {len(alignment)}\")\n",
    "print(f\"  ‚Ä¢ Mean absolute difference: {np.mean(differences):.6f}\")\n",
    "print(f\"  ‚Ä¢ Maximum difference: {np.max(differences):.6f}\")\n",
    "print(f\"  ‚Ä¢ Standard deviation of differences: {np.std(differences):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef5128",
   "metadata": {},
   "source": [
    "## Task 4: Plot the Alignment Path\n",
    "\n",
    "The alignment path visualization shows how samples in Signal 1 map to samples in the normalized Signal 2. After Linear Time Normalization, we expect to see:\n",
    "\n",
    "- **Linear Correspondence:** A diagonal line showing direct sample-to-sample mapping\n",
    "- **Perfect Alignment:** Each sample index in Signal 1 corresponds to the same index in normalized Signal 2\n",
    "- **Temporal Synchronization:** Both signals are now temporally aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5592b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create alignment visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Alignment Path\n",
    "signal1_indices = [pair[0] for pair in alignment]\n",
    "signal2_indices = [pair[1] for pair in alignment]\n",
    "\n",
    "axes[0].plot(signal1_indices, signal2_indices, 'bo-', linewidth=2.5, markersize=10, label='Alignment Path')\n",
    "axes[0].plot([0, len(signal1)-1], [0, len(signal1)-1], 'r--', linewidth=2, alpha=0.5, label='Perfect Linear Alignment')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlabel('Signal 1 Sample Index (Reference)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Normalized Signal 2 Sample Index', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Alignment Path: Linear Correspondence', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc='upper left', fontsize=11)\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "# Add annotations for start and end points\n",
    "axes[0].annotate('Start (0,0)', xy=(0, 0), xytext=(1, 1),\n",
    "                arrowprops=dict(arrowstyle='->', color='green', lw=2),\n",
    "                fontsize=10, fontweight='bold', color='green')\n",
    "axes[0].annotate(f'End ({len(signal1)-1},{len(signal1)-1})', \n",
    "                xy=(len(signal1)-1, len(signal1)-1), xytext=(len(signal1)-3, len(signal1)-2),\n",
    "                arrowprops=dict(arrowstyle='->', color='green', lw=2),\n",
    "                fontsize=10, fontweight='bold', color='green')\n",
    "\n",
    "# Plot 2: Sample-by-Sample Comparison\n",
    "x_pos = np.arange(len(signal1))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[1].bar(x_pos - width/2, signal1, width, label='Signal 1', alpha=0.8, color='blue')\n",
    "bars2 = axes[1].bar(x_pos + width/2, signal2_normalized, width, label='Normalized Signal 2', alpha=0.8, color='red')\n",
    "\n",
    "axes[1].set_xlabel('Sample Index', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Amplitude', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Sample-by-Sample Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='upper right', fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "axes[1].set_xticks(x_pos)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('task4_alignment_path.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìç ALIGNMENT PATH ANALYSIS:\")\n",
    "print(f\"  ‚Ä¢ The alignment path shows a perfect diagonal line\")\n",
    "print(f\"  ‚Ä¢ Each sample in Signal 1 maps to the same index in normalized Signal 2\")\n",
    "print(f\"  ‚Ä¢ This demonstrates successful linear time normalization\")\n",
    "print(f\"  ‚Ä¢ The signals are now temporally synchronized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eca516",
   "metadata": {},
   "source": [
    "## Additional Visualization: Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46498c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed error analysis visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Plot 1: Overlapped signals\n",
    "axes[0, 0].plot(time1, signal1, 'b-o', linewidth=2.5, markersize=8, label='Signal 1', alpha=0.7)\n",
    "axes[0, 0].plot(time1, signal2_normalized, 'r--^', linewidth=2.5, markersize=8, label='Normalized Signal 2', alpha=0.7)\n",
    "axes[0, 0].fill_between(time1, signal1, signal2_normalized, alpha=0.3, color='yellow')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_xlabel('Sample Index', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Amplitude', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_title('Overlapped Signals with Error Area', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend(loc='upper right')\n",
    "\n",
    "# Plot 2: Point-wise difference\n",
    "differences = signal1 - signal2_normalized\n",
    "colors = ['green' if d >= 0 else 'red' for d in differences]\n",
    "axes[0, 1].bar(time1, differences, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "axes[0, 1].set_xlabel('Sample Index', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Difference (Signal 1 - Normalized Signal 2)', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_title('Point-wise Differences', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot 3: Cumulative error\n",
    "cumulative_error = np.cumsum(np.abs(differences))\n",
    "axes[1, 0].plot(time1, cumulative_error, 'purple', linewidth=2.5, marker='s', markersize=8)\n",
    "axes[1, 0].fill_between(time1, 0, cumulative_error, alpha=0.3, color='purple')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_xlabel('Sample Index', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Cumulative Absolute Error', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_title('Cumulative Error Accumulation', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Plot 4: Scatter plot comparison\n",
    "axes[1, 1].scatter(signal1, signal2_normalized, s=100, alpha=0.7, c=time1, cmap='viridis', edgecolors='black', linewidth=1.5)\n",
    "axes[1, 1].plot([0, 1], [0, 1], 'r--', linewidth=2, label='Perfect Match (y=x)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_xlabel('Signal 1 Amplitude', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Normalized Signal 2 Amplitude', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_title('Amplitude Correlation Scatter Plot', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].legend(loc='upper left')\n",
    "axes[1, 1].set_aspect('equal')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1])\n",
    "cbar.set_label('Sample Index', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('error_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç ERROR ANALYSIS COMPLETED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabb3355",
   "metadata": {},
   "source": [
    "## Task 5: Inference and Conclusion\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "Based on our analysis of Linear Time Normalization for speech signal alignment, we can draw the following conclusions:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Time Axis Adjustment**\n",
    "Linear Time Normalization successfully adjusted the time axis of Signal 2 (slower speech with 12 samples) to match Signal 1 (faster speech with 9 samples). This was achieved through linear interpolation, which:\n",
    "- Compressed the temporal structure of Signal 2 by ~25%\n",
    "- Preserved the overall amplitude envelope and pattern\n",
    "- Enabled direct sample-to-sample comparison\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Pattern Alignment**\n",
    "After normalization, both signals exhibited:\n",
    "- **Similar temporal patterns:** The peak values aligned at the same relative positions\n",
    "- **Comparable amplitudes:** The normalized signal maintained amplitude characteristics close to the reference\n",
    "- **Linear correspondence:** A perfect diagonal alignment path, indicating successful temporal synchronization\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Speaking Speed Compensation**\n",
    "The normalization process effectively compensated for differences in speaking speed:\n",
    "- Signal 2 was originally 33.3% longer than Signal 1\n",
    "- Linear scaling compressed it to match the reference length\n",
    "- The envelope shapes remained consistent, showing the same word was spoken\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Practical Applications**\n",
    "Linear Time Normalization is valuable in speech processing for:\n",
    "- **Speech Recognition:** Normalizing different speaking rates before feature extraction\n",
    "- **Speaker Verification:** Comparing speech patterns from different utterance speeds\n",
    "- **Template Matching:** Aligning test signals with reference templates\n",
    "- **Preprocessing:** Standardizing speech duration before further analysis\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Limitations**\n",
    "While effective, Linear Time Normalization has limitations:\n",
    "- **Assumes uniform time warping:** Changes occur at a constant rate throughout\n",
    "- **May not capture non-linear variations:** Real speech often has non-uniform speed changes\n",
    "- **Information loss:** Some fine temporal details may be smoothed during interpolation\n",
    "- **Better alternatives exist:** Dynamic Time Warping (DTW) can handle non-linear time variations\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Conclusion**\n",
    "**Linear Time Normalization successfully aligns two speech signals of different lengths by linearly scaling the time axis.** This method is simple, computationally efficient, and effective when speed variations are relatively uniform. The alignment enables:\n",
    "- Direct comparison of temporal patterns\n",
    "- Calculation of similarity metrics\n",
    "- Matching of corresponding features\n",
    "\n",
    "For more complex scenarios with non-linear time warping, advanced techniques like Dynamic Time Warping (DTW) provide better alignment at the cost of increased computational complexity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e17990",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a64f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary\n",
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"FINAL SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"üìã SIGNAL CHARACTERISTICS:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"Signal 1 (Reference):\")\n",
    "print(f\"  ‚Ä¢ Length: {len(signal1)} samples\")\n",
    "print(f\"  ‚Ä¢ Range: [{signal1.min():.2f}, {signal1.max():.2f}]\")\n",
    "print(f\"  ‚Ä¢ Mean: {signal1.mean():.4f}\")\n",
    "print(f\"  ‚Ä¢ Std Dev: {signal1.std():.4f}\")\n",
    "print()\n",
    "print(f\"Signal 2 (Test - Original):\")\n",
    "print(f\"  ‚Ä¢ Length: {len(signal2)} samples\")\n",
    "print(f\"  ‚Ä¢ Range: [{signal2.min():.2f}, {signal2.max():.2f}]\")\n",
    "print(f\"  ‚Ä¢ Mean: {signal2.mean():.4f}\")\n",
    "print(f\"  ‚Ä¢ Std Dev: {signal2.std():.4f}\")\n",
    "print()\n",
    "print(f\"Signal 2 (Normalized):\")\n",
    "print(f\"  ‚Ä¢ Length: {len(signal2_normalized)} samples\")\n",
    "print(f\"  ‚Ä¢ Range: [{signal2_normalized.min():.4f}, {signal2_normalized.max():.4f}]\")\n",
    "print(f\"  ‚Ä¢ Mean: {signal2_normalized.mean():.4f}\")\n",
    "print(f\"  ‚Ä¢ Std Dev: {signal2_normalized.std():.4f}\")\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"üìä ALIGNMENT METRICS:\")\n",
    "print(\"-\"*70)\n",
    "differences = signal1 - signal2_normalized\n",
    "print(f\"Mean Squared Error (MSE): {np.mean(differences**2):.8f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {np.sqrt(np.mean(differences**2)):.8f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {np.mean(np.abs(differences)):.8f}\")\n",
    "print(f\"Maximum Absolute Error: {np.max(np.abs(differences)):.8f}\")\n",
    "print(f\"Correlation Coefficient: {np.corrcoef(signal1, signal2_normalized)[0,1]:.8f}\")\n",
    "print(f\"Cosine Similarity: {np.dot(signal1, signal2_normalized)/(np.linalg.norm(signal1)*np.linalg.norm(signal2_normalized)):.8f}\")\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"‚úÖ CONCLUSION:\")\n",
    "print(\"-\"*70)\n",
    "print(\"Linear Time Normalization successfully aligned both signals by:\")\n",
    "print(\"  1. Reducing Signal 2 from 12 to 9 samples\")\n",
    "print(\"  2. Preserving the amplitude envelope pattern\")\n",
    "print(\"  3. Creating a linear alignment path\")\n",
    "print(\"  4. Enabling direct temporal comparison\")\n",
    "print()\n",
    "print(f\"The high correlation ({np.corrcoef(signal1, signal2_normalized)[0,1]:.4f}) confirms\")\n",
    "print(\"successful alignment of temporal patterns despite different speaking speeds.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ab37e",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Rabiner, L., & Juang, B. H. (1993). *Fundamentals of Speech Recognition*. Prentice Hall.\n",
    "2. Sakoe, H., & Chiba, S. (1978). Dynamic programming algorithm optimization for spoken word recognition. *IEEE Transactions on Acoustics, Speech, and Signal Processing*, 26(1), 43-49.\n",
    "3. M√ºller, M. (2007). *Information Retrieval for Music and Motion*. Springer.\n",
    "4. SciPy Documentation: `scipy.interpolate.interp1d`\n",
    "\n",
    "---\n",
    "\n",
    "## End of Lab Exercise V\n",
    "\n",
    "**Student:** Alex  \n",
    "**Roll Number:** 2448507  \n",
    "**Date:** November 17, 2025"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
